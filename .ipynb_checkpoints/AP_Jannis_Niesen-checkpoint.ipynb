{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a47218",
   "metadata": {},
   "source": [
    "# Sonstige Beteiligung im Modul Angewandte Programmierung\n",
    "**Dozent: Herr Dennis Glüsenkamp**\n",
    "\n",
    "**Eingereicht von: Jannis Niesen**\n",
    "![alt text](69837.png \"Title\")\n",
    "\n",
    "### Inhaltsverzeichnis\n",
    "* [Business Understaning](#BusinessUnderstaning)\n",
    "* [Data Understanding und Data Preparation](#DataUnderstandingDataPreparation)\n",
    "* [Modelling](#Modelling)\n",
    "* [Evaluation](#Evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f368e4",
   "metadata": {},
   "source": [
    "## Vorhersage von Mietpreisen (Kaltmieten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85ef28",
   "metadata": {},
   "source": [
    "## Business Understanding<a class=\"anchor\" id=\"Business Understanding\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df0253",
   "metadata": {},
   "source": [
    "Bei dem Anwendungsfall geht es darum, Mietpreise von Wohnungen in Deutschland möglichst genau vorherzusagen. \n",
    "Dabei handelt es sich um ein Regressionsproblem, welches mit einem Supervised Learning Algorithmus gelöst werden kann.\n",
    "Die Daten kommen von dem Immobilienportal Immowelt. [[1]](#Immowelt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7ccb4",
   "metadata": {},
   "source": [
    "## Datenbeschaffung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d95d86",
   "metadata": {},
   "source": [
    "Um einen Datensatz mit Mietpreisen aus ganz Deutschland zu erstellen, wurde ein Webcrawler programmiert. Dieser sucht nach einem bestimmten Suchbegriff auf dem Imobilienportal Immowelt und extrahiert sowohl die Mietpreise, als auch andere Informationen, die für die Vorhersage dieser Mietpreise verwendet werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ef09a",
   "metadata": {},
   "source": [
    "### Immowelt Webcrawler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4fcc9",
   "metadata": {},
   "source": [
    "Der Code für den Webcrawler, einschließlich des verwendeten chromedrivers ist in auf github in dem Repository Immowelt_Crawler hochgeladen. [[2]](#Github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3da838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "def get_housing_data(search_term, n_sites):\n",
    "    \"\"\"\n",
    "    This function crawls information about apartments from immowelt.de.\n",
    "    The function uses a chromedriver to navigate the site and BeautifulSoup to pull data out of the HTML\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_term : str\n",
    "        The term to search for on immowelt.de\n",
    "    n_sites : int\n",
    "        Number of result pages to go through for each search term\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    pandas DataFrame\n",
    "        A DataFrame with the apartments on the first n_sites result pages containing six columns\n",
    "        (\"Description\", \"Price\", \"square-meters\", \"rooms\", \"address\", \"information\")\n",
    "    \"\"\"\n",
    "    # Input city to lowercase\n",
    "    search_term = search_term.lower()\n",
    "\n",
    "    # URL of target website\n",
    "    url = \"https://www.immowelt.de/\"\n",
    "\n",
    "    # load chrome webdriver with a Service\n",
    "    driver = webdriver.Chrome(service = Service(ChromeDriverManager().install()))\n",
    "\n",
    "    # call URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # look for search bar\n",
    "    search = driver.find_element(By.ID, 'tbLocationInput')\n",
    "\n",
    "    # type string in search bar\n",
    "    search.send_keys(search_term)\n",
    "\n",
    "    # press return\n",
    "    search.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Handling german Umlaute\n",
    "    character = {\"ä\": \"ae\", \"ö\": \"oe\", \"ü\": \"ue\", \"ß\": \"ss\"}\n",
    "    for char in character:\n",
    "        search_term = search_term.replace(char, character[char])\n",
    "\n",
    "    # wait for site to load\n",
    "    time.sleep(2)\n",
    "\n",
    "    # find apartments to click on\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    items = soup.find(\"div\", {\"class\": \"SearchList-22b2e\"})\n",
    "\n",
    "    result = []\n",
    "    # Loop through the first n sites\n",
    "    for i in range(1, n_sites + 1):\n",
    "        if i != 1:\n",
    "            # go to next site\n",
    "            driver.get(f\"https://www.immowelt.de/liste/{search_term}/wohnungen/mieten?d=true&sd=DESC&sf=RELEVANCE&sp={i}\")\n",
    "\n",
    "            time.sleep(2)\n",
    "            # find next apartments\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            items = soup.find(\"div\", {\"class\": \"SearchList-22b2e\"})\n",
    "\n",
    "        # check if there are apartments\n",
    "        if items is None:\n",
    "            break\n",
    "\n",
    "        # Loop through apartments and click all items (loop through children)\n",
    "        for item in items.children:\n",
    "            tag_element = item.findChild()\n",
    "\n",
    "            # check if NoneType\n",
    "            if tag_element is not None:\n",
    "                link = tag_element.get(\"href\")\n",
    "                driver.get(link)\n",
    "                time.sleep(2)\n",
    "\n",
    "                # get data\n",
    "                try:\n",
    "                    name = driver.find_element(By.XPATH, '// *[ @ id = \"aUebersicht\"] / h1')\n",
    "                    price = driver.find_element(By.XPATH,\n",
    "                                                '//*[@id=\"aUebersicht\"]/app-hardfacts/div/div/div[1]/div[1]/strong')\n",
    "                    sm = driver.find_element(By.XPATH,\n",
    "                                                 '//*[@id=\"aUebersicht\"]/app-hardfacts/div/div/div[2]/div[1]/span')\n",
    "                    rooms = driver.find_element(By.XPATH,\n",
    "                                                '//*[@id=\"aUebersicht\"]/app-hardfacts/div/div/div[2]/div[2]/span')\n",
    "                    address = driver.find_element(By.XPATH, '//*[@id=\"aUebersicht\"]/app-estate-address')\n",
    "                    info_1 = driver.find_element(By.XPATH, '//*[@id=\"aImmobilie\"]/sd-card')\n",
    "\n",
    "                    result.append([name.get_attribute(\"textContent\"), price.get_attribute(\"textContent\"),\n",
    "                                   sm.get_attribute(\"textContent\"), rooms.get_attribute(\"textContent\"),\n",
    "                                   address.get_attribute(\"textContent\"), info_1.get_attribute(\"textContent\")])\n",
    "                except:\n",
    "                    print(\"exception\")\n",
    "    # quit driver\n",
    "    driver.quit()\n",
    "\n",
    "    # result as pandas data frame\n",
    "    result = pd.DataFrame(result, columns=[\"Description\", \"Price\", \"square-meters\", \"rooms\", \"address\", \"information\"])\n",
    "    return (result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b197c56",
   "metadata": {},
   "source": [
    "### Informationen von Immowelt crawlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51554335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Webcrawler import get_housing_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# get germanys biggest city as crawler input\n",
    "cities = pd.read_excel(\"data/Gemeindeverzeichnis 2020.xlsx\")\n",
    "\n",
    "# Only bigger cities\n",
    "cities = cities[cities[\"Satz-art\"] == \"40\"]\n",
    "\n",
    "# Prepare for crawler\n",
    "cities = list(cities[\"Gemeindename\"].str.split(\",\").str[0])\n",
    "cities = cities[201:]\n",
    "\n",
    "# Call crawler function on citys\n",
    "housing_data_list = [get_housing_data(city, 5) for city in cities]\n",
    "\n",
    "housing_data = pd.concat(housing_data_list)\n",
    "\n",
    "# clean price and sm\n",
    "housing_data[\"Price\"] = housing_data[\"Price\"].apply(lambda x: x.replace(\"€\", \"\").replace(\".\", \"\").replace(\",\", \".\"))\n",
    "housing_data[\"square-meters\"] = housing_data[\"square-meters\"].apply(lambda x: x.replace(\"m²\", \"\").replace(\".\", \"\").replace(\",\", \".\"))\n",
    "\n",
    "# Excel\n",
    "housing_data.to_excel(\"housing_data3.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce8032",
   "metadata": {},
   "source": [
    "## Data Understanding und Data Preparation<a class=\"anchor\" id=\"#DataUnderstandingDataPreparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a4d80",
   "metadata": {},
   "source": [
    "### Erster Überblick über die Daten\n",
    "Der Datensatz besteht aus den 6 Variablen: Description, Price, square-meters, rooms, address, information, die alle als object gespeichert sind. Es gibt insgesammt 10483 Zeilen und die Variable Description hat 7 fehlende Werte. Ahand der ersten 5 Zeilen lässt sich erkennen, dass Description, address und price Zeichenketten sind. Price, square-meters und rooms sind numerische Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0132532e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10493 entries, 0 to 5296\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Description    10486 non-null  object\n",
      " 1   Price          10493 non-null  object\n",
      " 2   square-meters  10493 non-null  object\n",
      " 3   rooms          10493 non-null  object\n",
      " 4   address        10493 non-null  object\n",
      " 5   information    10493 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 573.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>square-meters</th>\n",
       "      <th>rooms</th>\n",
       "      <th>address</th>\n",
       "      <th>information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MODERNE und FREUNDLICHE 1-Zimmer-Wohnung in Fl...</td>\n",
       "      <td>600</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>Friesische Straße 2124937 Flensburg  (Friesisc...</td>\n",
       "      <td>Die WohnungKategorieApartmentWohnungslage1. Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wohnen an der Bergmühle - Gemütliche 3-Zimmer-...</td>\n",
       "      <td>839.37</td>\n",
       "      <td>79.94</td>\n",
       "      <td>3</td>\n",
       "      <td>Bauer Landstraße 1724939 Flensburg  (Nordstadt...</td>\n",
       "      <td>Die WohnungKategorieApartmentWohnungslage1. Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diakonie Betreutes Wohnen</td>\n",
       "      <td>430</td>\n",
       "      <td>58.46</td>\n",
       "      <td>2</td>\n",
       "      <td>Franz-Schubert-Hof 2024943 Flensburg  (Engelsb...</td>\n",
       "      <td>Die WohnungWohnungslageErdgeschossBezug01.06.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diakonie Betreutes Wohnen</td>\n",
       "      <td>350</td>\n",
       "      <td>43.18</td>\n",
       "      <td>2</td>\n",
       "      <td>Franz-Schubert-Hof  2024943 Flensburg  (Engels...</td>\n",
       "      <td>Die WohnungWohnungslage6. GeschossBezugab sofo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penthouse-Wohnung mit traumhaften Fördeblick</td>\n",
       "      <td>1540</td>\n",
       "      <td>104.26</td>\n",
       "      <td>3</td>\n",
       "      <td>Straße nicht freigegeben24944 Flensburg  (Mürw...</td>\n",
       "      <td>Die WohnungKategoriePenthouseWohnungslage4. Ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description    Price square-meters  \\\n",
       "0  MODERNE und FREUNDLICHE 1-Zimmer-Wohnung in Fl...     600            51    \n",
       "1  Wohnen an der Bergmühle - Gemütliche 3-Zimmer-...  839.37         79.94    \n",
       "2                          Diakonie Betreutes Wohnen     430         58.46    \n",
       "3                          Diakonie Betreutes Wohnen     350         43.18    \n",
       "4       Penthouse-Wohnung mit traumhaften Fördeblick    1540        104.26    \n",
       "\n",
       "  rooms                                            address  \\\n",
       "0     1  Friesische Straße 2124937 Flensburg  (Friesisc...   \n",
       "1     3  Bauer Landstraße 1724939 Flensburg  (Nordstadt...   \n",
       "2     2  Franz-Schubert-Hof 2024943 Flensburg  (Engelsb...   \n",
       "3     2  Franz-Schubert-Hof  2024943 Flensburg  (Engels...   \n",
       "4     3  Straße nicht freigegeben24944 Flensburg  (Mürw...   \n",
       "\n",
       "                                         information  \n",
       "0  Die WohnungKategorieApartmentWohnungslage1. Ge...  \n",
       "1  Die WohnungKategorieApartmentWohnungslage1. Ge...  \n",
       "2  Die WohnungWohnungslageErdgeschossBezug01.06.2...  \n",
       "3  Die WohnungWohnungslage6. GeschossBezugab sofo...  \n",
       "4  Die WohnungKategoriePenthouseWohnungslage4. Ge...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "# import geopandas as gpd\n",
    "from shapely.geometry import Polygon, LineString, Point\n",
    "import requests\n",
    "from numpy import nan\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# load crawler data\n",
    "housing_data = pd.read_excel(\"data/housing_data.xlsx\", index_col = 0)\n",
    "\n",
    "# throw out Unnamed\n",
    "housing_data = housing_data.drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "# inspect data\n",
    "housing_data.info()\n",
    "housing_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6625c7",
   "metadata": {},
   "source": [
    "### Geokoordinaten der Wohnungen joinen\n",
    "Über die Adresse lassen sich die Geokoordinaten (Breitengrad, Lägengrad) der Wohnungen ermitteln. Für diesen Zweck kann beispielsweise die kostenlose API OpenCage verwendet werden. Bei dieser kann man sich einen kostenlosen Account erstellen und dann bis zu 2500 Anfragen pro Tag senden. Die API sendet die Geokoordinaten der Wohnungen im JSON-Format. Aufgrund der Abfragenbeschränkung, wurden die Geokoordinaten über mehrere Tage verteilt abgerufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63311559",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'housing_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cleaning crawling data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m housing_data \u001b[38;5;241m=\u001b[39m \u001b[43mhousing_data\u001b[49m[\u001b[38;5;241m~\u001b[39mhousing_data\u001b[38;5;241m.\u001b[39maddress\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStraße nicht freigegeben\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      3\u001b[0m housing_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m housing_data\u001b[38;5;241m.\u001b[39maddress\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuf Karte ansehen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# get lat long from address\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'housing_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Cleaning crawling data\n",
    "housing_data = housing_data[~housing_data.address.str.contains(\"Straße nicht freigegeben\")]\n",
    "housing_data[\"address\"] = housing_data.address.str.replace(\"Auf Karte ansehen\", \"\")\n",
    "\n",
    "# get lat long from address\n",
    "coord_list = []\n",
    "\n",
    "# subset due to api limitations (2.5k per day)\n",
    "# housing_data = housing_data[:2500]\n",
    "housing_data = housing_data[:1]\n",
    "\n",
    "for index, row in housing_data.iterrows():\n",
    "    link = f\"https://api.opencagedata.com/geocode/v1/json?q={row.address}&key=bde3b179622541a9b24545f02697e461\"\n",
    "    response = requests.get(link)\n",
    "    try:\n",
    "        response = response.json()[\"results\"][0][\"geometry\"]\n",
    "    except:\n",
    "        response = {\"lat\": 0,\n",
    "                    \"lng\": 0}\n",
    "    coord_list.append(response)\n",
    "\n",
    "# create columns lat and lon\n",
    "housing_data[\"lat\"] = [appartement[\"lat\"] for appartement in coord_list]\n",
    "housing_data[\"lon\"] = [appartement[\"lng\"] for appartement in coord_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4818f23",
   "metadata": {},
   "source": [
    "### Zusätzliche unabhängige Variablen ermitteln\n",
    "#### Gemeindedaten\n",
    "Um Informationen über die Lage der Wohnung für die Prognose zu verwenden, wurden drei regionale Variablen hinzugefügt. Für diese Informationen müssen die Wohnungen allerdings zunächst Gemeinden zugeordnet werden. Dafür können die Verwaltungsgebiete vom Bundesamt für Kartographie und Geodäsie verwendet werden. [[3]](#Gemeindedaten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in xlsx\n",
    "housing_data = pd.read_excel(\"data/housing_data_cords.xlsx\")\n",
    "\n",
    "# read in shapefile data\n",
    "gemeinde_data = gpd.read_file(\"data/vg250_01-01.gk3.shape.ebenen/vg250_ebenen_0101/VG250_GEM.shp\")\n",
    "\n",
    "# set the crs (coordinate reference system)\n",
    "gemeinde_data = gemeinde_data.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# get gemeinde key from shapefile data\n",
    "gem_key = []\n",
    "\n",
    "# iterate through coordinates and get gemeinde key\n",
    "for index, row in housing_data.iterrows():\n",
    "    cord_point = Point(row.lon, row.lat)\n",
    "    bool_list = gemeinde_data.contains(cord_point)\n",
    "    try:\n",
    "        bool_index = bool_list[bool_list == True].index.values[0]\n",
    "        gem_key.append(gemeinde_data[\"SDV_ARS\"][bool_index])\n",
    "    except:\n",
    "        gem_key.append(\"\")\n",
    "\n",
    "housing_data[\"gemrs_20\"] = gem_key\n",
    "\n",
    "# load regiostar data\n",
    "regiostar = pd.read_excel(\"data/regiostar-referenzdateien.xlsx\", sheet_name = \"ReferenzGebietsstand2020\")\n",
    "\n",
    "regiostar[\"gemrs_20\"] = regiostar.gemrs_20.astype(\"string\")\n",
    "\n",
    "# remove leading zeros\n",
    "housing_data[\"gemrs_20\"] = [x.lstrip(\"0\") for x in housing_data[\"gemrs_20\"]]\n",
    "\n",
    "\n",
    "# join regiostar\n",
    "housing_data = pd.merge(housing_data, regiostar.loc[:, [\"gemrs_20\", \"RegioStaR7\"]], how = \"left\", on = \"gemrs_20\")\n",
    "\n",
    "# make var explainable\n",
    "housing_data[\"RegioStaR7\"] = housing_data[\"RegioStaR7\"].replace({71: \"Metropole\",\n",
    "                                                                 72: \"Regiopole\",\n",
    "                                                                 73: \"Großstadt\",\n",
    "                                                                 74: \"Zentrale Stadt\",\n",
    "                                                                 75: \"Mittelstadt\",\n",
    "                                                                 76: \"Städtischer Raum\",\n",
    "                                                                 77: \"Kleinstädtischer, dörflicher Raum\"})\n",
    "\n",
    "# clean df\n",
    "housing_data = housing_data.loc[:, \"Description\":]\n",
    "\n",
    "# fill to 12 digits\n",
    "housing_data[\"gemrs_20\"] = [x.zfill(12) for x in housing_data[\"gemrs_20\"]]\n",
    "\n",
    "# clean gemrs_20\n",
    "housing_data[\"gemrs_20\"] = [x[0:9] for x in housing_data[\"gemrs_20\"]]\n",
    "\n",
    "# Join Bevölkerung\n",
    "bev_data = pd.read_excel(\"data/Gemeindeverzeichnis 2020.xlsx\", dtype = {\"gem_20\": str})\n",
    "bev_data = bev_data[~bev_data[\"Bev_Insgesamt\"].isna()]\n",
    "\n",
    "housing_data = pd.merge(housing_data, bev_data[[\"gem_20\", \"Fläche km2 \", \"Bev_Insgesamt\"]], how = \"left\", left_on = \"gemrs_20\", right_on = \"gem_20\")\n",
    "\n",
    "# Rename\n",
    "housing_data = housing_data.rename(columns= {\"Fläche km2 \": \"gem_size_km2\",\n",
    "                                             \"Bev_Insgesamt\": \"gem_population\",\n",
    "                                             \"Description\": \"description\",\n",
    "                                             \"Price\": \"price\",\n",
    "                                             \"RegioStarR7\": \"regioStarR7\"})\n",
    "\n",
    "housing_data = housing_data.drop(columns=[\"gem_20\", \"gemrs_20\"])\n",
    "\n",
    "# remove duplicates\n",
    "housing_data = housing_data.drop_duplicates(subset = [\"description\", \"price\", \"address\", \"square-meters\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe22a5",
   "metadata": {},
   "source": [
    "#### Balcony und floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a few variables\n",
    "housing_data[\"balcony\"] = [\"Balkon\" in x or \"balkon\" in x for x in housing_data[\"information\"]]\n",
    "\n",
    "housing_data[\"floor\"] = [x[x.find(\"Geschoss\") - 3:x.find(\"Geschoss\")-2] for x in housing_data[\"information\"]]\n",
    "\n",
    "# Erdgeschoss\n",
    "floor = []\n",
    "for index, row in housing_data.iterrows():\n",
    "    if row[\"floor\"].isnumeric():\n",
    "        floor.append(row[\"floor\"])\n",
    "    else:\n",
    "        floor.append(\"Erdgeschoss\" in row[\"information\"] or \"erdgeschoss\" in row[\"information\"])\n",
    "\n",
    "housing_data[\"floor\"] = floor\n",
    "\n",
    "# Ergeschoss = 0, missing = nan\n",
    "housing_data[\"floor\"] = [nan if x == False else 0 if x == True else x for x in housing_data[\"floor\"]]\n",
    "\n",
    "# no need for information and address anymore\n",
    "housing_data = housing_data.drop(columns=[\"information\", \"address\"])\n",
    "\n",
    "# clean price\n",
    "housing_data[\"price\"] = [float(x) if any(char.isdigit() for char in x) else 0 for x in housing_data.price]\n",
    "housing_data = housing_data[housing_data[\"price\"] >0]\n",
    "\n",
    "# Number of words per Desription\n",
    "housing_data = housing_data[~housing_data[\"description\"].isna()]\n",
    "housing_data[\"description\"] = housing_data[\"description\"].astype(\"string\")\n",
    "housing_data[\"des_length\"] = [len(des.split()) for des in housing_data[\"description\"]]\n",
    "\n",
    "housing_data = housing_data.drop(columns=\"description\")\n",
    "\n",
    "\n",
    "housing_data.to_excel(\"data/housing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics as st\n",
    "import matplotlib.ticker as mtick\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import branca\n",
    "import branca.colormap as cm\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Read in data\n",
    "housing_data = pd.read_excel(\"data/housing.xlsx\", index_col=0, decimal = \",\")\n",
    "housing_data[\"floor\"] = housing_data[\"floor\"].astype(\"string\")\n",
    "housing_data = housing_data[housing_data[\"square-meters\"] != \"kA\"]\n",
    "housing_data[\"square-meters\"] = housing_data[\"square-meters\"].astype(\"float64\")\n",
    "housing_data = housing_data[housing_data[\"rooms\"] != \"k.A.\"]\n",
    "housing_data[\"rooms\"] = housing_data[\"rooms\"].astype(\"float64\")\n",
    "\n",
    "\n",
    "# settings for printing in console\n",
    "width = 320\n",
    "pd.set_option(\"display.width\", width)\n",
    "np.set_printoptions(linewidth=width)\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "\n",
    "# First look at the data\n",
    "print(housing_data.head())\n",
    "\n",
    "housing_data.info()\n",
    "\n",
    "print(housing_data.describe())\n",
    "\n",
    "\n",
    "# Analyse price\n",
    "# Outlier?\n",
    "price_boxplot = plt.boxplot(housing_data.price)\n",
    "plt.xlabel(\"price\")\n",
    "plt.title(\"Boxplot price\")\n",
    "plt.show()\n",
    "\n",
    "# Remove outliers and nans\n",
    "housing_data = housing_data[~housing_data[\"price\"].isnull()]\n",
    "per25, per75 = np.percentile(housing_data.price, [25, 75])\n",
    "outlier = (per75 - per25) * 1.5 + per75\n",
    "\n",
    "housing_data = housing_data[housing_data[\"price\"] <= outlier]\n",
    "\n",
    "\n",
    "# Function Histogramm\n",
    "def histo(data, var):\n",
    "    \"\"\"\n",
    "    This function creates a histogram based on the variable specified in var.\n",
    "    The y-axis shows the relation as percentage. The red line marks the median value of var.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas DataFrame\n",
    "        The dataset containing var\n",
    "    var : str\n",
    "        The variable to plot a histogram with\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    matplotlib pyplot\n",
    "        A histogram showing the distribution of the variable var\n",
    "    \"\"\"\n",
    "    plt.hist(data[var], bins=20, color=\"b\", edgecolor=\"k\", weights=np.ones(len(data[var])) / len(data[var]))\n",
    "    plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "    plt.axvline(data[var].median(), color=\"r\", linestyle=\"dashed\")\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel(\"Count %\")\n",
    "    plt.title(f'Histogram {var}')\n",
    "    plt.tick_params(axis=\"x\", rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Histogram of price\n",
    "histo(housing_data, \"price\")\n",
    "\n",
    "# Remove obvious outliers and clean data\n",
    "housing_data = housing_data[housing_data[\"square-meters\"] <= 500]\n",
    "housing_data = housing_data[housing_data[\"rooms\"] < 7.0]\n",
    "housing_data = housing_data[housing_data[\"rooms\"] != 2.1]\n",
    "\n",
    "# Encode RegioStaR7\n",
    "encoder = LabelEncoder()\n",
    "housing_data[\"RegioStaR7\"] = encoder.fit_transform(housing_data[\"RegioStaR7\"])\n",
    "\n",
    "\n",
    "# Verteilung aller erklärenden Variablen in einem Plot\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "# square-meters\n",
    "plt.subplot(3, 3, 1)\n",
    "housing_data = housing_data[housing_data[\"square-meters\"] != \"kA\"]\n",
    "housing_data[\"square-meters\"] = housing_data[\"square-meters\"].astype(\"float\")\n",
    "histo(housing_data, \"square-meters\")\n",
    "\n",
    "plt.subplot(3, 3, 2)\n",
    "# gem_size_km2\n",
    "histo(housing_data, \"gem_size_km2\")\n",
    "\n",
    "plt.subplot(3, 3, 3)\n",
    "# gem_population\n",
    "histo(housing_data[housing_data[\"gem_population\"] < 1000000], \"gem_population\")\n",
    "\n",
    "# des_length\n",
    "plt.subplot(3, 3, 4)\n",
    "histo(housing_data, \"des_length\")\n",
    "\n",
    "# function bar chart\n",
    "def bar(data, var):\n",
    "    \"\"\"\n",
    "    This function creates a bar chart based on the variable specified in var.\n",
    "    The y-axis shows the relation as percentage.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas DataFrame\n",
    "        The dataset containing var\n",
    "    var : str\n",
    "        The variable to plot a bar chart with\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    matplotlib pyplot\n",
    "        A bar chart showing the distribution of the variable var\n",
    "    \"\"\"\n",
    "    df = data.groupby(var)[var].count().to_frame()\n",
    "    df = pd.DataFrame({\"value\": df.index, \"percentage\": df[var] / len(data)})\n",
    "    df = df[df[\"percentage\"] >= 0.001]\n",
    "    df = df.sort_values(\"percentage\", ascending=False).reset_index()\n",
    "    df[\"value\"] = df[\"value\"].astype(\"string\")\n",
    "    df = df[df[\"percentage\"] >= 0.01]\n",
    "\n",
    "    df_plot = sns.barplot(x=\"value\", y=\"percentage\", data=df)\n",
    "    for index, value in enumerate(df.percentage):\n",
    "        plt.text(index, value + 0.001,\n",
    "                 f\"{value:.1%}\", ha=\"center\")\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel(\"Count %\")\n",
    "    plt.ylim(0, df[\"percentage\"][0] + 0.05)\n",
    "    plt.title(f'Barchart {var}')\n",
    "    df_plot.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=None, symbol='%', is_latex=False))\n",
    "    plt.tick_params(axis=\"x\", rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# rooms\n",
    "plt.subplot(3, 3, 5)\n",
    "bar(housing_data, \"rooms\")\n",
    "\n",
    "# RegioStaR7\n",
    "plt.subplot(3, 3, 6)\n",
    "bar(housing_data, \"RegioStaR7\")\n",
    "\n",
    "# balcony\n",
    "plt.subplot(3, 3, 7)\n",
    "bar(housing_data, \"balcony\")\n",
    "\n",
    "# floor\n",
    "plt.subplot(3, 3, 8)\n",
    "bar(housing_data, \"floor\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.35, hspace=0.35)\n",
    "plt.suptitle(\"Distribution variables\")\n",
    "\n",
    "\n",
    "\n",
    "# Plot lat long with Folium and Leaflet\n",
    "# https://www.earthdatascience.org/tutorials/introduction-to-leaflet-animated-maps/\n",
    "germany_coords = [51.163361, 10.447683]\n",
    "\n",
    "# build map\n",
    "germany_map = folium.Map(location=germany_coords, zoom_start=7)\n",
    "\n",
    "# add flats\n",
    "for index, row in housing_data.iterrows():\n",
    "    folium.Marker(location=[row[\"lat\"], row[\"lon\"]]).add_to(germany_map)\n",
    "\n",
    "# save map\n",
    "germany_map.save(\"germany_map.html\")\n",
    "\n",
    "# There are flats outside of germany\n",
    "# Remove those\n",
    "# bb of germany\n",
    "housing_data = housing_data[housing_data[\"lat\"].between(47.3024876979, 54.983104153) &\n",
    "                            housing_data[\"lon\"].between(5.98865807458, 15.0169958839)]\n",
    "\n",
    "\n",
    "# Price and lat lon\n",
    "# https://medium.com/analytics-vidhya/create-and-visualize-choropleth-map-with-folium-269d3fd12fa0\n",
    "# build map\n",
    "germany_map_price = folium.Map(location=germany_coords, zoom_start=7)\n",
    "\n",
    "# create color palette\n",
    "palette = cm.LinearColormap(colors=[\"yellow\", \"red\"],\n",
    "                            vmin = housing_data.price.min(), vmax=housing_data.price.max())\n",
    "\n",
    "# add flats\n",
    "for index, row in housing_data.iterrows():\n",
    "    folium.CircleMarker(location=[row[\"lat\"], row[\"lon\"]], radius = 14,\n",
    "                  fill = True, color = palette(row[\"price\"]), popup = str(row[\"price\"])).add_to(germany_map_price)\n",
    "\n",
    "germany_map_price.add_child(palette)\n",
    "# save map\n",
    "germany_map_price.save(\"germany_map_price.html\")\n",
    "\n",
    "# Fill missing values\n",
    "\n",
    "# Are there missing values?\n",
    "# NAs\n",
    "housing_data.info()\n",
    "NAS = housing_data.isna().sum().to_frame(\"Nas\")\n",
    "NAS = pd.DataFrame({\"variable\": NAS.index, \"percentage\": (NAS.Nas / len(housing_data))* 100})\n",
    "NAS = NAS[NAS[\"percentage\"] >0]\n",
    "NAS = NAS.sort_values(\"percentage\", ascending=False).reset_index()\n",
    "\n",
    "# Remove the few gem_size_km2 and gem_population nas\n",
    "housing_data = housing_data[~housing_data[\"gem_size_km2\"].isna()]\n",
    "\n",
    "# There are too many nas in floor to remove all of them\n",
    "# Fill with median\n",
    "housing_data[\"floor\"] = housing_data[\"floor\"].astype(\"float\")\n",
    "housing_data[\"floor\"].fillna(housing_data[\"floor\"].median(), inplace=True)\n",
    "\n",
    "# There are no nas left\n",
    "housing_data.info()\n",
    "\n",
    "# Understanding relationships\n",
    "# Price and all other variables\n",
    "# scatter function\n",
    "def scatter_plot(data, var_x, var_y):\n",
    "    \"\"\"\n",
    "    This function creates a scatter plot with var_x on the x-axis and var_y on the y-axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas DataFrame\n",
    "        The dataset containing var_x and var_y\n",
    "    var_x : str\n",
    "        The variable on the x-axis\n",
    "    var_y : str\n",
    "        The variable on the y-axis\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    matplotlib pyplot\n",
    "        A scatter plot with the variables var_x and var_y\n",
    "    \"\"\"\n",
    "    plt.scatter(x=var_x, y=var_y, data = data)\n",
    "    plt.xlabel(var_x)\n",
    "    plt.ylabel(var_y)\n",
    "    plt.title(f'Scatterplot {var_x} & {var_y}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# boxplot function\n",
    "def box(data, var_x, var_y):\n",
    "    \"\"\"\n",
    "    This function creates a boxplot with var_x on the x-axis and var_y on the y-axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas DataFrame\n",
    "        The dataset containing var_x and var_y\n",
    "    var_x : str\n",
    "        The variable on the x-axis\n",
    "    var_y : str\n",
    "        The variable on the y-axis\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    matplotlib pyplot\n",
    "        A boxplot with the variables var_x and var_y\n",
    "    \"\"\"\n",
    "    order = data.groupby(var_x).median().sort_values(var_y)\n",
    "    sns.boxplot(x=var_x, y = var_y, order = order.index, data = data)\n",
    "    plt.xlabel(var_x)\n",
    "    plt.ylabel(var_y)\n",
    "    plt.title(f'Boxplot {var_x} & {var_y}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "# square-meters\n",
    "plt.subplot(4, 3, 1)\n",
    "scatter_plot(housing_data, \"square-meters\", \"price\")\n",
    "\n",
    "# lat\n",
    "plt.subplot(4, 3, 2)\n",
    "scatter_plot(housing_data, \"lat\", \"price\")\n",
    "\n",
    "# lon\n",
    "plt.subplot(4, 3, 3)\n",
    "scatter_plot(housing_data, \"lon\", \"price\")\n",
    "\n",
    "# gem_size_km2\n",
    "plt.subplot(4, 3, 4)\n",
    "scatter_plot(housing_data, \"gem_size_km2\", \"price\")\n",
    "\n",
    "# gem_population\n",
    "plt.subplot(4, 3, 5)\n",
    "scatter_plot(housing_data, \"gem_population\", \"price\")\n",
    "\n",
    "# des_length\n",
    "plt.subplot(4, 3, 6)\n",
    "scatter_plot(housing_data, \"des_length\", \"price\")\n",
    "\n",
    "# rooms\n",
    "plt.subplot(4, 3, 7)\n",
    "box(housing_data, \"rooms\", \"price\")\n",
    "\n",
    "# RegiostaR7\n",
    "plt.subplot(4, 3, 8)\n",
    "box(housing_data, \"RegioStaR7\", \"price\")\n",
    "\n",
    "# balcony\n",
    "plt.subplot(4, 3, 9)\n",
    "box(housing_data, \"balcony\", \"price\")\n",
    "\n",
    "# floor\n",
    "plt.subplot(4, 3, 10)\n",
    "box(housing_data, \"floor\", \"price\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.35, hspace=0.35)\n",
    "plt.suptitle(\"Compare price to the other variables\")\n",
    "\n",
    "housing_data.to_excel(\"data/housing_data_prepped.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79da0ba",
   "metadata": {},
   "source": [
    "## Modelling<a class=\"anchor\" id=\"Modelling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee165527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "housing_data = pd.read_excel(\"data/housing_data_prepped.xlsx\", index_col=0, decimal = \",\")\n",
    "\n",
    "# train and test split\n",
    "housing_train, housing_test = train_test_split(housing_data,\n",
    "                                               test_size=0.2,\n",
    "                                               random_state=3)\n",
    "\n",
    "# Random Forest with Cross Validation\n",
    "housing_DT = RandomForestRegressor(random_state=3)\n",
    "housing_params = {\"min_samples_split\": [2, 3, 3, 4],\n",
    "                  \"max_features\": [4, 5, 6, 7, 8],\n",
    "                  \"max_samples\": [0.5, 0.6, 0.7,  0.8],\n",
    "                  \"max_depth\": [14, 16, 18, 20]}\n",
    "\n",
    "housing_CV = GridSearchCV(housing_DT, housing_params, cv = 3)\n",
    "\n",
    "# create fit\n",
    "housing_CV.fit(housing_train.drop(columns=\"price\"), housing_train[\"price\"])\n",
    "housing_CV_res = pd.DataFrame(housing_CV.cv_results_).sort_values(by=[\"rank_test_score\"])\n",
    "\n",
    "# feature importance\n",
    "housing_importance = pd.DataFrame({\"variables\": housing_data.drop(columns=\"price\").columns,\n",
    "                                   \"FI\": housing_CV.best_estimator_.feature_importances_})\n",
    "\n",
    "housing_importance = housing_importance.sort_values(\"FI\", ascending=False).reset_index()\n",
    "\n",
    "sns.barplot(x=\"variables\", y=\"FI\", data= housing_importance)\n",
    "for index, value in enumerate(housing_importance.FI):\n",
    "    plt.text(index, value,\n",
    "             str(round(value, 2)), ha=\"center\")\n",
    "plt.xlabel(\"variables\")\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "plt.title(f'Feature Importance Housing')\n",
    "plt.tight_layout()\n",
    "\n",
    "# make predictions with test data\n",
    "housing_preds = housing_CV.predict(housing_test.drop(columns=\"price\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641c466",
   "metadata": {},
   "source": [
    "## Evaluation<a class=\"anchor\" id=\"Evaluation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd46a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(housing_test[\"price\"], housing_preds, squared=False))\n",
    "print(mean_absolute_error(housing_test[\"price\"], housing_preds))\n",
    "\n",
    "# Analyse predictions\n",
    "plt.scatter(housing_test[\"price\"], housing_preds)\n",
    "plt.plot([housing_test[\"price\"].min(), housing_test[\"price\"].max()],\n",
    "         [housing_test[\"price\"].min(), housing_test[\"price\"].max()], \"k--\", lw=4)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Predicted price')\n",
    "plt.title(\"Actual price vs. predicted price\")\n",
    "plt.show()\n",
    "\n",
    "housing_test.insert(1, \"preds\", housing_preds)\n",
    "housing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9e2b1",
   "metadata": {},
   "source": [
    "## Quellen\n",
    "\n",
    "[1] <a class=\"anchor\" id=\"Immowelt\"></a>Immowelt: https://www.immowelt.de/\n",
    "\n",
    "[2] <a class=\"anchor\" id=\"Github\"></a>Github Immowelt_Crawler: https://github.com/LeIx1999/Immowelt_Crawler\n",
    "\n",
    "[3] <a class=\"anchor\" id=\"Gemeindedaten\"></a>Bundesamt für Kartographie und Geodäsie: https://gdz.bkg.bund.de/index.php/default/digitale-geodaten/verwaltungsgebiete/verwaltungsgebiete-1-5-000-000-ebenen-stand-31-12-vg5000-ebenen-12-31.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d77d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
